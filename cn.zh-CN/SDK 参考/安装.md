# 安装 {#concept_bmh_bdf_qfb .concept}

本文档主要介绍文件系统 SDK 的安装及使用方式。

本节以 hadoop-mapreduce-examples 为例，介绍文件系统 SDK 的使用方式。其中 MapReduce 以伪分布式方式运行。有关 MapReduce 的伪分布方式，请参见 [Apache Hadoop](https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SingleCluster.html#Pseudo-Distributed_Operation) 文档说明。

## 环境准备 {#section_t4s_ndf_qfb .section}

1.  运行java ‐version查看 JDK 版本。

    JDK 版本不能低于 1.8。

2.  安装完成后，按照以下方式设置环境变量，假设安装位置为/opt/install/java。

    ```
    JAVA_HOME=/opt/install/java
    PATH=/opt/install/java/bin:$PATH
    ```


## 下载 SDK {#section_chx_xdf_qfb .section}

您可以单击[此处](https://mvnrepository.com/artifact/com.aliyun.dfs/aliyun-sdk-dfs)下载 DFS 文件系统 SDK 的 JAR文件alicloud.dfs-x.y.z.jar。

## 配置 Hadoop {#section_gxc_c2f_qfb .section}

1.  下载 hadoop 2.7.2 发布包。
2.  运行tar ‐zxvf hadoop‐2.7.2.tar.gz命令，解压缩下载的发布包。
3.  运行export HADOOP\_HOME=yourWorkingDir/hadoop‐2.7.2命令，设置环境变量。
4.  运行cd hadoop-2.7.2命令，进入 Hadoop 目录。
5.  修改etc/hadoop/hadoop-env.sh文件，并增加环境准备中设置的`JAVA_HOME`：

    ```
    # set to the root of your Java installation
    export JAVA_HOME=youJAVADirt
    ```

6.  修改etc/hadoop/core-site.xml文件，core-site.xml 文件中需要修改的内容如下所示：

    ```
    <property>
    <name>fs.defaultFS</name>
    <value>dfs://DfsInstanceID.RegionID.alidfs.aliyun.com:10290</value>
    </property>
    <property>
    <name>fs.dfs.impl</name>
    <value>com.alibaba.dfs.DistributedFileSystem</value>
    </property>
    <property>
    <name>fs.AbstractFileSystem.dfs.impl</name>
    <value>com.alibaba.dfs.DFS</value>
    </property>
    
    ```

    **说明：** 

    -   请将 RegionID 和 DfsInstanceID 替换为具体 DFS 实例的相应内容。
    -   core-site.xml的内容需要同步到所有依赖`hadoop-common`的节点上。

## 部署依赖 {#section_ikk_zff_qfb .section}

将上述步骤中获得的alicloud.dfs-x.y.z.jar 拷贝至 Hadoop 生态系统组件的 CLASSPATH 上。推荐将其部署到hadoop-common-x.y.z.jar所在的目录内，并复制到所有 Hadoop 节点。对于 MapReduce 组件，该目录为$HADOOP\_HOME/share/hadoop/hdfs。

## 验证安装 {#section_ymj_fgf_qfb .section}

1.  准备数据
    1.  运行以下命令创建目录：

        ```
        $HADOOP_HOME/bin/hadoop fs ‐mkdir inputDir
        ```

    2.  运行以下命令上传文件：

        ```
        touch a.txt
        $HADOOP_HOME/bin/hadoop fs ‐put a.txt inputDir/
        ```

2.  执行样例

    在$HADOOP\_HOME下执行以下样例：

    -   wordcount 样例

        ```
        bin/hadoop jar ./share/hadoop/mapreduce/hadoop‐mapreduce‐examples‐2.7.2.jar wordcount
        inputDir outputDir
        ```

    -   grep 样例

        ```
        bin/hadoop jar ./share/hadoop/mapreduce/hadoop‐mapreduce‐examples‐2.7.2.jar grep
        inputDir/ outputDirGrep/ "the"
        ```


